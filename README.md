# 어떤 프로젝트 인가?
![https://github.com/user-attachments/assets/612cdc17-7472-497e-9c9e-964d3b4ec3a0](https://media1.tenor.com/m/YcXXO5zvNuQAAAAC/simpsons-bart-simpson.gif)

이 프로젝트는 임베디드 프로그램에서 실시한 젯슨과 아두이노, 메가 2560을 이용한 CCTV 얼굴 잠지 프로그램 입니다.

# 어떤 기기를 사용했나요?
## Jeston Orin AGX 
젯슨으로 해용해서 얼굴 학습 및 얼굴 탐지, 움직임 탐지등  연산이 필요한 부분을 처리 해주는 기기입니다.

## Arduino && mega2560 && ESP9866  
젯슨에서 탐지 하는 결과 값을 통지를 받기 위한 임베디드 보입니다.<br>
데이터를 통신하기 위해 ESP를 사용했고 Arduino && mega2560은 2개 합쳐진 보드가<br>
있어서 결과 값을 출력하기 위해 사용 했습니다.

# Rapberry PI
CCTV를 역할 하고 웹캠과 RSTP 프로토콜을 이용해서 젯슨과 통신하기 위해 사용했습니다.

# 어떻게 작동하나요?
## 얼굴 학습
![image](https://github.com/user-attachments/assets/436680cb-2b9a-4675-83b7-b92bb9a4ab7a)
1. 사용자는 특정 URL을 들어갑니다.
2. 사이트에서 웹캡 권한을 흑득하고 시작 버튼을 눌려수 45초동안 좌우 위아래 움직이면서 얼굴을 확인합니다.
3. 영상을 다 찍은경우 서버에서 보내져서 서버에서는 영상을 3초에 한프레임씩 사진을 뽑아서 Opencv을 통해서 1차 전처리 하고
4. 각 프레임마다 얼굴의 특징(눈,코,입,턱선)을 탐지를 해서 좌표를 남김니다.
5. 이 데이터를 이용해서 처리한 파일을 내보내서 저장합니다. (1사진당 1파일)

## 얼굴 탐지
![image](https://github.com/user-attachments/assets/cc392a72-2c65-4c79-88cc-fd22095926e6)
1. CCTV에서 영상을 실시간으로 받아서 Opencv를 이용해서 움직임을 탐지합니다.
2. 만약 움직임이 확인이 되는경우 얼굴을 탐지를 시작합니다.
3. 영상에서 얼굴이 확인이 되면 얼굴을 추출해서 분석을 합니다.
4. 분석한 결과를 토대로 임베디드에 MQTT 프로토콜을 이용해서 결과를 전송합니다.
